{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84026eb-d172-45c6-8776-33e53a61f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000f2cd1-7662-45d8-bce3-758403b69bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read JSON file and prepare documents\n",
    "\n",
    "with open ('./documents.json', 'rt') as f_in:\n",
    "    doc_file = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in doc_file:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73a79bb-57df-4496-8314-aee02934897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ids using the contents of the docunets\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    # combines the content of the documents\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2ec156-c9df-41dd-ad07-24479765658f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    doc['id'] = generate_document_id(doc)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1453f5-2641-46c0-a916-3fc74612c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save documents with ids\n",
    "\n",
    "with open('documents-with-ids.json', 'wt') as f_out:\n",
    "    json.dump(documents, f_out, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84653459-3c59-4613-bd7c-f228ebd361c2",
   "metadata": {},
   "source": [
    "#### **Text generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041284b5-abde-407a-8d4e-1d37d6bdc739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = \"\"\"\n",
    "You emulate a student who's taking our course.\n",
    "Formulate 5 questions this student might ask based on a FAQ record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dc7c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fce2e250810>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e87375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5621522042e8431dadd1d213f7fc9280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\", \n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68cc47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb646c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    # Format the prompt using the document data\n",
    "    prompt = prompt_template.format(**doc)\n",
    "    \n",
    "    # Generate questions using the pipeline\n",
    "    response = pipe(prompt, max_new_tokens=200, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95, temperature=0.7)\n",
    "    \n",
    "    # Extract and return the generated text\n",
    "    generated_text = response[0]['generated_text']\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbf8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save results to a file\n",
    "\n",
    "def save_results(results, filename='results.json'):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        json.dump(results, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c253231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3665c688918466eb003a70b20631006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Load intermediate results if any\n",
    "try:\n",
    "    with open('results.json', 'r') as f_in:\n",
    "        results = json.load(f_in)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Process each document and save results periodically\n",
    "for doc in tqdm(documents):\n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    results[doc_id] = questions\n",
    "\n",
    "    # Save the results after processing each document\n",
    "    save_results(results)\n",
    "\n",
    "# Save the final results\n",
    "save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b04653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You emulate a student who\\'s taking our course.\\nFormulate 5 questions this student might ask based on a FAQ record. The record\\nshould contain the answer to the questions, and the questions should be complete and not too short.\\nIf possible, use as fewer words as possible from the record. \\n\\nThe record:\\n\\nsection: Module 5: pyspark\\nquestion: PicklingError: Could not serialize object: IndexError: tuple index out of range\\nanswer: This version combination worked for me:\\nPySpark = 3.3.2\\nPandas = 1.5.3\\n\\nIf it still has an error,\\n\\nProvide the output in parsable JSON without using code blocks:\\n\\n[\"question1\", \"question2\", ..., \"question5\"]\\n\\n\\n# Answer\\n\\n[\\n  \"I\\'m getting a PicklingError related to a tuple index out of range when working with PySpark. Can you suggest which versions of PySpark and Pandas might resolve this issue?\",\\n  \"During my PySpark module work, I encountered a PicklingError with an IndexError regarding a tuple. What version combinations of PySpark and Pandas could potentially fix this error?\",\\n  \"While using PySpark in Module 5, I came across a PicklingError because of a tuple index out of range. Which versions of PySpark and Pandas should I use to avoid this error?\",\\n  \"I\\'m facing a PicklingError with an IndexError tuple in my PySpark module. Could you recommend the appropriate versions of PySpark and Pandas to prevent this error?\",\\n  \"I\\'m working on PySpark in Module 5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['06014eec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c50fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
